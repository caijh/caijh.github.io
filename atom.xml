<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://caijh.github.io/</id>
    <title>John&apos;s Blog</title>
    <updated>2019-07-15T03:48:32.649Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://caijh.github.io/"/>
    <link rel="self" href="https://caijh.github.io//atom.xml"/>
    <subtitle>搬砖大佬</subtitle>
    <logo>https://caijh.github.io//images/avatar.png</logo>
    <icon>https://caijh.github.io//favicon.ico</icon>
    <rights>All rights reserved 2019, John&apos;s Blog</rights>
    <entry>
        <title type="html"><![CDATA[Redis - 过期删除策略]]></title>
        <id>https://caijh.github.io//post/redis-guo-qi-shan-chu-ce-lue</id>
        <link href="https://caijh.github.io//post/redis-guo-qi-shan-chu-ce-lue">
        </link>
        <updated>2019-07-15T03:18:31.000Z</updated>
        <summary type="html"><![CDATA[<p>Redis 采用的过期策略： 懒汉式删除 + 定期删除</p>
]]></summary>
        <content type="html"><![CDATA[<p>Redis 采用的过期策略： 懒汉式删除 + 定期删除</p>
<!-- more -->
<h1 id="三种过期删除策略">三种过期删除策略</h1>
<h2 id="定时删除">定时删除</h2>
<p>设置key的过期时间的同时为key设置一个定时器，在key过期时对key进行删除。<br>
优点： 保证内存被尽快回收。<br>
缺点：</p>
<ol>
<li>若key过多，删除key占用CPU时间</li>
<li>定时器的创建耗时，若对每个key创建定时器，会有大量定时器产生，影响性能</li>
</ol>
<h2 id="懒汉式删除">懒汉式删除</h2>
<p>在访问key的时候，判断key是否过期，如过期，删除key.<br>
优点： 删除操作只发生个获取key的时候，对CPU占用少<br>
缺点：若大量key超时，但很长一段时间内都没有访问，那些key会一直占用内存，可能会有内存泄漏</p>
<h2 id="定期删除">定期删除</h2>
<p>每隔一段时间执行一次删除过期key<br>
优点：</p>
<ol>
<li>减少对CPU的占用</li>
<li>克服懒汉式删除的缺点<br>
缺点：获取的key可以已经是过期的</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL - explain详解]]></title>
        <id>https://caijh.github.io//post/mysql-explain-xiang-jie</id>
        <link href="https://caijh.github.io//post/mysql-explain-xiang-jie">
        </link>
        <updated>2019-07-14T15:23:40.000Z</updated>
        <content type="html"><![CDATA[<h5 id="explain详解">Explain详解</h5>
<ol>
<li>
<p>ID列</p>
<p>ID值不同时, 执行计划由ID大的向ID小读; ID值相同时, 执行计划由上到下读</p>
</li>
<li>
<p>SELECT_TYPE列</p>
<table>
<thead>
<tr>
<th>值</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIMPLE</td>
<td style="text-align:left">不包含子查询或UNION操作的查询</td>
</tr>
<tr>
<td>PRIMARY</td>
<td style="text-align:left">查询中如果包含了子查询,那么最外层的查询会被标为primary</td>
</tr>
<tr>
<td>SUBQUERY</td>
<td style="text-align:left">select列表中的子查询</td>
</tr>
<tr>
<td>dependent subquery</td>
<td style="text-align:left">依赖外部结果的子查询</td>
</tr>
<tr>
<td>Union</td>
<td style="text-align:left">Union操作的第二个表之后的查询值为union</td>
</tr>
<tr>
<td>Dependent union</td>
<td style="text-align:left">当union作为子查询, 第二或第二个后的查询select_type</td>
</tr>
<tr>
<td>Union result</td>
<td style="text-align:left">union产生的结果集</td>
</tr>
<tr>
<td>Derived</td>
<td style="text-align:left">出现在from子句中的子查询</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>table列</p>
<p>表的名称或者表的别名.</p>
<p>unionM,N 由ID为M,N查询union产生的结果集</p>
<p>derivedN or subqueryN 表示由ID为N的查询产生结果集</p>
</li>
<li>
<p>partition列</p>
<p>对于分区表, 显示查询的分区id; 非分区表显示NULL</p>
</li>
<li>
<p>Type列</p>
<p>查询中使用了联结的类型</p>
<table>
<thead>
<tr>
<th>值</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>System</td>
<td>这是const联接类型中的一个特例, 当查询的表中只在一行显示</td>
</tr>
<tr>
<td>const</td>
<td>表中有且只有一个匹配的行时使用, 如主键或者唯一索引的查询</td>
</tr>
<tr>
<td>eq_ref</td>
<td>唯一索引或主键查找, 对于每个索引键, 表中只有一条记录与之匹配</td>
</tr>
<tr>
<td>ref</td>
<td>非唯一索引查找, 返回匹配某个单独值的所有行</td>
</tr>
<tr>
<td>ref_or_null</td>
<td>类似于ref类型的查询, 但是附加了对NULL值列的查询</td>
</tr>
<tr>
<td>index_merge</td>
<td>表示使用了索引合并</td>
</tr>
<tr>
<td>range</td>
<td>索引范围</td>
</tr>
<tr>
<td>index</td>
<td>Full index Scan全索引扫描,</td>
</tr>
<tr>
<td>all</td>
<td>全表扫描</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Extra列</p>
<table>
<thead>
<tr>
<th>值</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>Distinct</td>
<td>优化distinct操作, 找到第一匹配的元组后暂停找同样值的动作</td>
</tr>
<tr>
<td>Not Exists</td>
<td>使用Not Exists来优化查询</td>
</tr>
<tr>
<td>Using filesort</td>
<td>使用额外操作进行排序</td>
</tr>
<tr>
<td>Using index</td>
<td>使用了覆盖索引进行查询</td>
</tr>
<tr>
<td>Using temporary</td>
<td>需要使用临时表处理查询</td>
</tr>
<tr>
<td>Using where</td>
<td>需要在服务层使用where条件过滤</td>
</tr>
<tr>
<td>select tables optimized away</td>
<td>直接通过索引来获得数据, 不用访问表</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>possible_keys 列</p>
<p>指出MySQL能使用哪些索引来优化查询, 查询列所涉及的列上的索引都会被列出, 但不一定会被使用.</p>
</li>
<li>
<p>Key列</p>
<p>查询优化器优化查询实际所使用索引列</p>
</li>
<li>
<p>Key_len列</p>
<p>表示索引字段的最大可能长度</p>
</li>
<li>
<p>ref列</p>
<p>表示哪些列或常量被用于查询索引列上的值</p>
</li>
<li>
<p>rows列</p>
<p>表示MySQL通过索引统计信息, 估算的需要读取的行数, 是一个统计抽样结果, 并不十分准确</p>
</li>
<li>
<p>filtered列</p>
<p>表示返回结果的行数占需要读取行数的百分比, 值越大越好</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[源码阅读 - AbstractQueuedSynchronizer]]></title>
        <id>https://caijh.github.io//post/yuan-dai-ma-abstractqueuedsynchronizer</id>
        <link href="https://caijh.github.io//post/yuan-dai-ma-abstractqueuedsynchronizer">
        </link>
        <updated>2019-07-14T10:38:40.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>AbstractQueuedSynchronizer, 简称AQS, 是Java 并发包的基础类，并发包中的很多api都是基于AQS来实现加锁与释放锁等功能。</p>
</blockquote>
<p>例如ReentrantLock内部拥有一个继承于AbstractQueuedSynchronizer的Sync类实现加锁与释放锁。<br>
AQS内部有一个state状态记录当前线程的加锁次数，还有一个exclusiveOwnerThread变量记录了独占的线程。</p>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>AbstractQueuedSynchronizer, 简称AQS, 是Java 并发包的基础类，并发包中的很多api都是基于AQS来实现加锁与释放锁等功能。</p>
</blockquote>
<p>例如ReentrantLock内部拥有一个继承于AbstractQueuedSynchronizer的Sync类实现加锁与释放锁。<br>
AQS内部有一个state状态记录当前线程的加锁次数，还有一个exclusiveOwnerThread变量记录了独占的线程。</p>
<!-- more -->
<pre><code>
    /**
     * Creates an instance of {@code ReentrantLock} with the
     * given fairness policy.
     *
     * @param fair {@code true} if this lock should use a fair ordering policy
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
</code></pre>
<p>ReentrantLock可以是公平的也可以不非公平的。</p>
<pre><code>/**
     * Acquires in exclusive mode, ignoring interrupts.  Implemented
     * by invoking at least once {@link #tryAcquire},
     * returning on success.  Otherwise the thread is queued, possibly
     * repeatedly blocking and unblocking, invoking {@link
     * #tryAcquire} until success.  This method can be used
     * to implement method {@link Lock#lock}.
     *
     * @param arg the acquire argument.  This value is conveyed to
     *        {@link #tryAcquire} but is otherwise uninterpreted and
     *        can represent anything you like.
     */
    public final void acquire(int arg) {
        if (!tryAcquire(arg) &amp;&amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</code></pre>
<p>AQS中的加锁，申请不到锁，加入等待队列。</p>
<pre><code>/**
     * Sync object for fair locks
     */
    static final class FairSync extends Sync {
        private static final long serialVersionUID = -3000897897090466540L;
        /**
         * Fair version of tryAcquire.  Don't grant access unless
         * recursive call or no waiters or is first.
         */
        @ReservedStackAccess
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &amp;&amp;
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc &lt; 0)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                setState(nextc);
                return true;
            }
            return false;
        }
    }
</code></pre>
<p>hasQueuedPredecessors看等待队列中是否有线程在排队。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Cloud - 如何解决Feign/Ribbon第一次请求失败的问题]]></title>
        <id>https://caijh.github.io//post/spring-cloud-ru-he-jie-jue-feignribbon-di-yi-ci-qing-qiu-shi-bai-de-wen-ti</id>
        <link href="https://caijh.github.io//post/spring-cloud-ru-he-jie-jue-feignribbon-di-yi-ci-qing-qiu-shi-bai-de-wen-ti">
        </link>
        <updated>2019-07-13T14:43:38.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>造成该问题的原因？<br>
Hystrix默认的超时时间是1秒，如果超过这个时间尚未响应，将会进入fallback代码。而首次请求往往会比较慢（由于Ribbon是懒加载的，在首次请求时，才会开始初始化相关类），这个响应时间可能就大于1秒了。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>造成该问题的原因？<br>
Hystrix默认的超时时间是1秒，如果超过这个时间尚未响应，将会进入fallback代码。而首次请求往往会比较慢（由于Ribbon是懒加载的，在首次请求时，才会开始初始化相关类），这个响应时间可能就大于1秒了。</p>
</blockquote>
<!-- more -->
<h4 id="1-将hystrix的超时设长">1. 将Hystrix的超时设长</h4>
<pre><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000
</code></pre>
<h4 id="2-禁用hystrix超时">2. 禁用Hystrix超时</h4>
<pre><code>hystrix.command.default.execution.timeout.enabled: false
</code></pre>
<h4 id="3-为feign禁用hystrix">3. 为Feign禁用Hystrix</h4>
<p>全局禁用</p>
<pre><code>feign.hystrix.enabled: false
</code></pre>
<p>局部禁用</p>
<pre><code>@FeignClient(name = &quot;microservice-provider-user&quot;)
public interface UserFeignClient {
  @GetMapping(&quot;/users/{id}&quot;)
  User findById(@PathVariable(&quot;id&quot;) Long id);
}
class FooConfiguration {
  @Bean
  @Scope(&quot;prototype&quot;)
  public Feign.Builder feignBuilder(){
    return Feign.builder();
  }
}
</code></pre>
<h4 id="4-ribbon配置饥饿加载">4. Ribbon配置饥饿加载</h4>
<pre><code>ribbon:
  eager-load:
    enabled: true
    clients: client1, client2, client3
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java - 线程池]]></title>
        <id>https://caijh.github.io//post/java-xian-cheng-chi</id>
        <link href="https://caijh.github.io//post/java-xian-cheng-chi">
        </link>
        <updated>2019-07-08T10:49:35.000Z</updated>
        <summary type="html"><![CDATA[<h4 id="threadpoolexecutor的重要参数">ThreadPoolExecutor的重要参数</h4>
<ul>
<li>corePoolSize：核心线程数<br>
核心线程会一直存活，及时没有任务需要执行<br>
当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理<br>
设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭</li>
<li>queueCapacity：任务队列容量（阻塞队列）<br>
当核心线程数达到最大时，新任务会放在队列中排队等待执行</li>
<li>maxPoolSize：最大线程数<br>
当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务<br>
当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常</li>
<li>keepAliveTime：线程空闲时间<br>
当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize<br>
如果allowCoreThreadTimeout=true，则会直到线程数量=0</li>
<li>allowCoreThreadTimeout：允许核心线程超时</li>
<li>rejectedExecutionHandler：任务拒绝处理器<br>
两种情况会拒绝处理任务：<br>
当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务<br>
当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务<br>
线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常<br>
ThreadPoolExecutor类有几个内部实现类来处理这类情况：<br>
AbortPolicy 丢弃任务，抛运行时异常<br>
CallerRunsPolicy 执行任务<br>
DiscardPolicy 忽视，什么都不会发生<br>
DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务<br>
实现RejectedExecutionHandler接口，可自定义处理器</li>
</ul>
]]></summary>
        <content type="html"><![CDATA[<h4 id="threadpoolexecutor的重要参数">ThreadPoolExecutor的重要参数</h4>
<ul>
<li>corePoolSize：核心线程数<br>
核心线程会一直存活，及时没有任务需要执行<br>
当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理<br>
设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭</li>
<li>queueCapacity：任务队列容量（阻塞队列）<br>
当核心线程数达到最大时，新任务会放在队列中排队等待执行</li>
<li>maxPoolSize：最大线程数<br>
当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务<br>
当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常</li>
<li>keepAliveTime：线程空闲时间<br>
当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize<br>
如果allowCoreThreadTimeout=true，则会直到线程数量=0</li>
<li>allowCoreThreadTimeout：允许核心线程超时</li>
<li>rejectedExecutionHandler：任务拒绝处理器<br>
两种情况会拒绝处理任务：<br>
当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务<br>
当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务<br>
线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常<br>
ThreadPoolExecutor类有几个内部实现类来处理这类情况：<br>
AbortPolicy 丢弃任务，抛运行时异常<br>
CallerRunsPolicy 执行任务<br>
DiscardPolicy 忽视，什么都不会发生<br>
DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务<br>
实现RejectedExecutionHandler接口，可自定义处理器</li>
</ul>
<!-- more -->
<h4 id="threadpoolexecutor执行顺序">ThreadPoolExecutor执行顺序：</h4>
<pre><code> 线程池按以下行为执行任务
</code></pre>
<ol>
<li>当线程数小于核心线程数时，创建线程。</li>
<li>当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。</li>
<li>当线程数大于等于核心线程数，且任务队列已满<br>
3.1 若线程数小于最大线程数，创建线程<br>
3.2 若线程数等于最大线程数，抛出异常，拒绝任务</li>
</ol>
<p>三、如何设置参数</p>
<ul>
<li>默认值<br>
corePoolSize=1<br>
queueCapacity=Integer.MAX_VALUE<br>
maxPoolSize=Integer.MAX_VALUE<br>
keepAliveTime=60s<br>
allowCoreThreadTimeout=false<br>
rejectedExecutionHandler=AbortPolicy()</li>
</ul>
<blockquote>
<p>如何来设置?</p>
</blockquote>
<ol>
<li>需要根据几个值来决定<br>
tasks ：每秒的任务数，假设为500~1000<br>
taskcost：每个任务花费时间，假设为0.1s<br>
responsetime：系统允许容忍的最大响应时间，假设为1s</li>
<li>做几个计算</li>
</ol>
<ul>
<li>corePoolSize = 每秒需要多少个线程处理？<br>
threadcount = tasks/(1/taskcost) =tasks*taskcout =  (500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50<br>
根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可</li>
<li>queueCapacity = (coreSizePool/taskcost)<em>responsetime<br>
计算可得 queueCapacity = 80/0.1</em>1 = 800。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行<br>
切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。</li>
<li>maxPoolSize = (max(tasks)- queueCapacity)/(1/taskcost) + corePoolSize<br>
计算可得 maxPoolSize = (1000-800)/10 +80 = 100<br>
（最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数</li>
<li>rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理</li>
<li>keepAliveTime和allowCoreThreadTimeout采用默认通常能满足<br>
以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件（呵呵）和优化代码，降低taskcost来处理。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka-Acks参数]]></title>
        <id>https://caijh.github.io//post/kafka-acks-can-shu</id>
        <link href="https://caijh.github.io//post/kafka-acks-can-shu">
        </link>
        <updated>2019-07-06T15:16:29.000Z</updated>
        <summary type="html"><![CDATA[<p>kafka中用topic表示同类的消息，topic可以有1个或多个partition.<br>
kafka集群中一个broker负责一部分partition，在kafka集群中，每个Partition都有多个副本，其中一个副本叫做leader，其他的副本叫做follower。</p>
]]></summary>
        <content type="html"><![CDATA[<p>kafka中用topic表示同类的消息，topic可以有1个或多个partition.<br>
kafka集群中一个broker负责一部分partition，在kafka集群中，每个Partition都有多个副本，其中一个副本叫做leader，其他的副本叫做follower。</p>
<!-- more -->
<h4 id="多副本之间如何同步">多副本之间如何同步？</h4>
<p>其实任何一个Partition，只有副本Leader是对外提供读写服务的，然后Leader副本接收到数据之后，Follower副本会不停的给他发送请求尝试去拉取最新的数据，拉取到自己本地后，写入磁盘中。</p>
<h4 id="isr是指什么">ISR是指什么？</h4>
<p>ISR全称是“In-Sync Replicas”，也就是保持同步的副本，他的含义就是，跟Leader始终保持同步的Follower有哪些。<br>
每个Partition都有一个ISR，这个ISR里一定会有Leader自己，因为Leader肯定数据是最新的，然后就是那些跟Leader保持同步的Follower，也会在ISR里。</p>
<h4 id="acks参数">acks参数</h4>
<ul>
<li>acks = 0， KafkaProducer在客户端，只要把消息发送出去，不管那条数据有没有在哪怕Partition Leader上落到磁盘，我就不管他了，直接就认为这个消息发送成功了。如果你采用这种设置的话，那么你必须注意的一点是，可能你发送出去的消息还在半路。结果呢，Partition Leader所在Broker就直接挂了，然后结果你的客户端还认为消息发送成功了，此时就会导致这条消息就丢失了。</li>
<li>acks =1， Partition Leader接收到消息而且写入本地磁盘了，就认为成功了，不管他其他的Follower有没有同步过去这条消息了。但是这里有一个问题，万一Partition Leader刚刚接收到消息，Follower还没来得及同步过去，结果Leader所在的broker宕机了，此时也会导致这条消息丢失，因为人家客户端已经认为发送成功了。</li>
<li>acks = -1 (all), Partition Leader接收到消息之后，还必须要求ISR列表里跟Leader保持同步的那些Follower都要把消息同步过去，才能认为这条消息是写入成功了。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[源码阅读-tomcat]]></title>
        <id>https://caijh.github.io//post/yuan-ma-yue-du-tomcat</id>
        <link href="https://caijh.github.io//post/yuan-ma-yue-du-tomcat">
        </link>
        <updated>2019-07-06T14:18:45.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="tomcat启动过程">tomcat启动过程</h1>
<p><img src="https://caijh.github.io//post-images/1562423239997.jpg" alt=""></p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="tomcat启动过程">tomcat启动过程</h1>
<p><img src="https://caijh.github.io//post-images/1562423239997.jpg" alt=""></p>
<!-- more -->
<ol>
<li>
<p>获取Bootstrap的静态代码块获取catalinaBaseFile及catalinaHomeFile</p>
<pre><code class="language-java">static {
        // Will always be non-null
        String userDir = System.getProperty(&quot;user.dir&quot;);

        // Home first
        String home = System.getProperty(Globals.CATALINA_HOME_PROP);
        File homeFile = null;

        if (home != null) {
            File f = new File(home);
            try {
                homeFile = f.getCanonicalFile();
            } catch (IOException ioe) {
                homeFile = f.getAbsoluteFile();
            }
        }

        if (homeFile == null) {
            // First fall-back. See if current directory is a bin directory
            // in a normal Tomcat install
            File bootstrapJar = new File(userDir, &quot;bootstrap.jar&quot;);

            if (bootstrapJar.exists()) {
                File f = new File(userDir, &quot;..&quot;);
                try {
                    homeFile = f.getCanonicalFile();
                } catch (IOException ioe) {
                    homeFile = f.getAbsoluteFile();
                }
            }
        }

        if (homeFile == null) {
            // Second fall-back. Use current directory
            File f = new File(userDir);
            try {
                homeFile = f.getCanonicalFile();
            } catch (IOException ioe) {
                homeFile = f.getAbsoluteFile();
            }
        }

        catalinaHomeFile = homeFile;
        System.setProperty(
                Globals.CATALINA_HOME_PROP, catalinaHomeFile.getPath());

        // Then base
        String base = System.getProperty(Globals.CATALINA_BASE_PROP);
        if (base == null) {
            catalinaBaseFile = catalinaHomeFile;
        } else {
            File baseFile = new File(base);
            try {
                baseFile = baseFile.getCanonicalFile();
            } catch (IOException ioe) {
                baseFile = baseFile.getAbsoluteFile();
            }
            catalinaBaseFile = baseFile;
        }
        System.setProperty(
                Globals.CATALINA_BASE_PROP, catalinaBaseFile.getPath());
    }

</code></pre>
</li>
<li>
<p>Bootstrap的main方法执行init, load,start</p>
<pre><code class="language-java">public static void main(String args[]) {

        synchronized (daemonLock) {
            if (daemon == null) {
                // Don't set daemon until init() has completed
                Bootstrap bootstrap = new Bootstrap();
                try {
                    bootstrap.init();
                } catch (Throwable t) {
                    handleThrowable(t);
                    t.printStackTrace();
                    return;
                }
                daemon = bootstrap;
            } else {
                // When running as a service the call to stop will be on a new
                // thread so make sure the correct class loader is used to
                // prevent a range of class not found exceptions.
                Thread.currentThread().setContextClassLoader(daemon.catalinaLoader);
            }
        }

        try {
            String command = &quot;start&quot;;
            if (args.length &gt; 0) {
                command = args[args.length - 1];
            }

            if (command.equals(&quot;startd&quot;)) {
                args[args.length - 1] = &quot;start&quot;;
                daemon.load(args);
                daemon.start();
            } else if (command.equals(&quot;stopd&quot;)) {
                args[args.length - 1] = &quot;stop&quot;;
                daemon.stop();
            } else if (command.equals(&quot;start&quot;)) {
                daemon.setAwait(true);
                daemon.load(args);
                daemon.start();
                if (null == daemon.getServer()) {
                    System.exit(1);
                }
            } else if (command.equals(&quot;stop&quot;)) {
                daemon.stopServer(args);
            } else if (command.equals(&quot;configtest&quot;)) {
                daemon.load(args);
                if (null == daemon.getServer()) {
                    System.exit(1);
                }
                System.exit(0);
            } else {
                log.warn(&quot;Bootstrap: command \&quot;&quot; + command + &quot;\&quot; does not exist.&quot;);
            }
        } catch (Throwable t) {
            // Unwrap the Exception for clearer error reporting
            if (t instanceof InvocationTargetException &amp;&amp;
                    t.getCause() != null) {
                t = t.getCause();
            }
            handleThrowable(t);
            t.printStackTrace();
            System.exit(1);
        }

    }
</code></pre>
</li>
<li>
<p>Bootstrap init方法</p>
<pre><code class="language-java">public void init() throws Exception {

        initClassLoaders();

        Thread.currentThread().setContextClassLoader(catalinaLoader);

        SecurityClassLoad.securityClassLoad(catalinaLoader);

        // Load our startup class and call its process() method
        if (log.isDebugEnabled())
            log.debug(&quot;Loading startup class&quot;);
        Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;);
        Object startupInstance = startupClass.getConstructor().newInstance();

        // Set the shared extensions class loader
        if (log.isDebugEnabled())
            log.debug(&quot;Setting startup class properties&quot;);
        String methodName = &quot;setParentClassLoader&quot;;
        Class&lt;?&gt; paramTypes[] = new Class[1];
        paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;);
        Object paramValues[] = new Object[1];
        paramValues[0] = sharedLoader;
        Method method =
            startupInstance.getClass().getMethod(methodName, paramTypes);
        method.invoke(startupInstance, paramValues);

        catalinaDaemon = startupInstance;

    }
</code></pre>
</li>
<li>
<p>Bootstrap load方法，会调用catalina.load()</p>
<pre><code class="language-java">    private void load(String[] arguments)
        throws Exception {

        // Call the load() method
        String methodName = &quot;load&quot;;
        Object param[];
        Class&lt;?&gt; paramTypes[];
        if (arguments==null || arguments.length==0) {
            paramTypes = null;
            param = null;
        } else {
            paramTypes = new Class[1];
            paramTypes[0] = arguments.getClass();
            param = new Object[1];
            param[0] = arguments;
        }
        Method method =
            catalinaDaemon.getClass().getMethod(methodName, paramTypes);
        if (log.isDebugEnabled())
            log.debug(&quot;Calling startup class &quot; + method);
        method.invoke(catalinaDaemon, param);

    }
</code></pre>
</li>
<li>
<p>catalina load</p>
<pre><code class="language-java">public void load() {

        if (loaded) {
            return;
        }
        loaded = true;

        long t1 = System.nanoTime();

        initDirs();

        // Before digester - it may be needed
        initNaming();

        // Set configuration source
        ConfigFileLoader.setSource(new CatalinaBaseConfigurationSource(Bootstrap.getCatalinaBaseFile(), getConfigFile()));
        File file = configFile();

        // Create and execute our Digester
        Digester digester = createStartDigester();

        try (ConfigurationSource.Resource resource = ConfigFileLoader.getSource().getServerXml()) {
            InputStream inputStream = resource.getInputStream();
            InputSource inputSource = new InputSource(resource.getURI().toURL().toString());
            inputSource.setByteStream(inputStream);
            digester.push(this);
            digester.parse(inputSource);
        } catch (Exception e) {
            log.warn(sm.getString(&quot;catalina.configFail&quot;, file.getAbsolutePath()), e);
            if (file.exists() &amp;&amp; !file.canRead()) {
                log.warn(sm.getString(&quot;catalina.incorrectPermissions&quot;));
            }
            return;
        }

        getServer().setCatalina(this);
        getServer().setCatalinaHome(Bootstrap.getCatalinaHomeFile());
        getServer().setCatalinaBase(Bootstrap.getCatalinaBaseFile());

        // Stream redirection
        initStreams();

        // Start the new server
        try {
            getServer().init();
        } catch (LifecycleException e) {
            if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;)) {
                throw new java.lang.Error(e);
            } else {
                log.error(sm.getString(&quot;catalina.initError&quot;), e);
            }
        }

        long t2 = System.nanoTime();
        if(log.isInfoEnabled()) {
            log.info(sm.getString(&quot;catalina.init&quot;, Long.valueOf((t2 - t1) / 1000000)));
        }
    }
</code></pre>
</li>
<li>
<p>Server的初始化init方法，会调用service init方法，在其中又完成了engine, executor, connector的init</p>
<pre><code class="language-JAVA">protected void initInternal() throws LifecycleException {

        super.initInternal();

        if (engine != null) {
            engine.init();
        }

        // Initialize any Executors
        for (Executor executor : findExecutors()) {
            if (executor instanceof JmxEnabled) {
                ((JmxEnabled) executor).setDomain(getDomain());
            }
            executor.init();
        }

        // Initialize mapper listener
        mapperListener.init();

        // Initialize our defined Connectors
        synchronized (connectorsLock) {
            for (Connector connector : connectors) {
                connector.init();
            }
        }
    }
</code></pre>
</li>
<li>
<p>Bootstrap调用start方法</p>
</li>
</ol>
<h1 id="connector的初始化过程">Connector的初始化过程</h1>
<p><img src="https://caijh.github.io//post-images/1562423283434.jpg" alt=""></p>
<ol>
<li>
<p>Connector对象的创建</p>
<pre><code class="language-java">public Connector(String protocol) {
        boolean aprConnector = AprLifecycleListener.isAprAvailable() &amp;&amp;
                AprLifecycleListener.getUseAprConnector();

        if (&quot;HTTP/1.1&quot;.equals(protocol) || protocol == null) {
            if (aprConnector) {
                protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11AprProtocol&quot;;
            } else {
                protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11NioProtocol&quot;;
            }
        } else if (&quot;AJP/1.3&quot;.equals(protocol)) {
            if (aprConnector) {
                protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpAprProtocol&quot;;
            } else {
                protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpNioProtocol&quot;;
            }
        } else {
            protocolHandlerClassName = protocol;
        }

        // Instantiate protocol handler
        ProtocolHandler p = null;
        try {
            Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName);
            p = (ProtocolHandler) clazz.getConstructor().newInstance();
        } catch (Exception e) {
            log.error(sm.getString(
                    &quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;), e);
        } finally {
            this.protocolHandler = p;
        }

        // Default for Connector depends on this system property
        setThrowOnFailure(Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;));
    }
</code></pre>
</li>
<li>
<p>Connector初始化</p>
<pre><code class="language-java">@Override
protected void initInternal() throws LifecycleException {

    super.initInternal();

    if (protocolHandler == null) {
        throw new LifecycleException(
                sm.getString(&quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;));
    }

    // Initialize adapter
    adapter = new CoyoteAdapter(this);
    protocolHandler.setAdapter(adapter);
    if (service != null) {
        protocolHandler.setUtilityExecutor(service.getServer().getUtilityExecutor());
    }

    // Make sure parseBodyMethodsSet has a default
    if (null == parseBodyMethodsSet) {
        setParseBodyMethods(getParseBodyMethods());
    }

    if (protocolHandler.isAprRequired() &amp;&amp; !AprLifecycleListener.isInstanceCreated()) {
        throw new LifecycleException(sm.getString(&quot;coyoteConnector.protocolHandlerNoAprListener&quot;,
                getProtocolHandlerClassName()));
    }
    if (protocolHandler.isAprRequired() &amp;&amp; !AprLifecycleListener.isAprAvailable()) {
        throw new LifecycleException(sm.getString(&quot;coyoteConnector.protocolHandlerNoAprLibrary&quot;,
                getProtocolHandlerClassName()));
    }
    if (AprLifecycleListener.isAprAvailable() &amp;&amp; AprLifecycleListener.getUseOpenSSL() &amp;&amp;
            protocolHandler instanceof AbstractHttp11JsseProtocol) {
        AbstractHttp11JsseProtocol&lt;?&gt; jsseProtocolHandler =
                (AbstractHttp11JsseProtocol&lt;?&gt;) protocolHandler;
        if (jsseProtocolHandler.isSSLEnabled() &amp;&amp;
                jsseProtocolHandler.getSslImplementationName() == null) {
            // OpenSSL is compatible with the JSSE configuration, so use it if APR is available
            jsseProtocolHandler.setSslImplementationName(OpenSSLImplementation.class.getName());
        }
    }

    try {
        protocolHandler.init();
    } catch (Exception e) {
        throw new LifecycleException(
                sm.getString(&quot;coyoteConnector.protocolHandlerInitializationFailed&quot;), e);
    }
}
</code></pre>
</li>
<li>
<p>protocalHandle的init</p>
<pre><code class="language-java">@Override
    public void init() throws Exception {
        if (getLog().isInfoEnabled()) {
            getLog().info(sm.getString(&quot;abstractProtocolHandler.init&quot;, getName()));
            logPortOffset();
        }

        if (oname == null) {
            // Component not pre-registered so register it
            oname = createObjectName();
            if (oname != null) {
                Registry.getRegistry(null, null).registerComponent(this, oname, null);
            }
        }

        if (this.domain != null) {
            rgOname = new ObjectName(domain + &quot;:type=GlobalRequestProcessor,name=&quot; + getName());
            Registry.getRegistry(null, null).registerComponent(
                    getHandler().getGlobal(), rgOname, null);
        }

        String endpointName = getName();
        endpoint.setName(endpointName.substring(1, endpointName.length()-1));
        endpoint.setDomain(domain);

        endpoint.init();
    }
</code></pre>
</li>
<li>
<p>endpoint的init</p>
<pre><code class="language-java">public final void init() throws Exception {
    if (bindOnInit) {
        bindWithCleanup();
        bindState = BindState.BOUND_ON_INIT;
    }
    if (this.domain != null) {
        // Register endpoint (as ThreadPool - historical name)
        oname = new ObjectName(domain + &quot;:type=ThreadPool,name=\&quot;&quot; + getName() + &quot;\&quot;&quot;);
        Registry.getRegistry(null, null).registerComponent(this, oname, null);

        ObjectName socketPropertiesOname = new ObjectName(domain +
                &quot;:type=ThreadPool,name=\&quot;&quot; + getName() + &quot;\&quot;,subType=SocketProperties&quot;);
        socketProperties.setObjectName(socketPropertiesOname);
        Registry.getRegistry(null, null).registerComponent(socketProperties, socketPropertiesOname, null);

        for (SSLHostConfig sslHostConfig : findSslHostConfigs()) {
            registerJmx(sslHostConfig);
        }
    }
}
</code></pre>
</li>
<li>
<p>Connector的start方法调用protocalHandle的start方法，protocalHandle再调用endpoint的start方法，AbstractEndpoint中start方法如下</p>
<pre><code class="language-java">public final void start() throws Exception {
    if (bindState == BindState.UNBOUND) {
        bindWithCleanup();
        bindState = BindState.BOUND_ON_START;
    }
    startInternal();
}
</code></pre>
</li>
<li>
<p>Endpoint的start</p>
<pre><code class="language-java">public void startInternal() throws Exception {

    if (!running) {
        running = true;
        paused = false;

        processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,
                socketProperties.getProcessorCache());
        eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,
                        socketProperties.getEventCache());
        nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,
                socketProperties.getBufferPool());

        // Create worker collection
        if ( getExecutor() == null ) {
            createExecutor();
        }

        initializeConnectionLatch();

        // Start poller threads
        pollers = new Poller[getPollerThreadCount()];
        for (int i=0; i&lt;pollers.length; i++) {
            pollers[i] = new Poller();
            Thread pollerThread = new Thread(pollers[i], getName() + &quot;-ClientPoller-&quot;+i);
            pollerThread.setPriority(threadPriority);
            pollerThread.setDaemon(true);
            pollerThread.start();
        }

        startAcceptorThreads();
    }
}
</code></pre>
</li>
</ol>
<h1 id="tomcat处理用户请求过程">tomcat处理用户请求过程</h1>
<p>Connector的内部结构</p>
<p><img src="/Users/caijunhui/Library/Application%20Support/typora-user-images/image-20190405183952839.png" alt="image-20190405183952839"></p>
<p>Acceptor负责接收用户的请求，设置Socket属性，向poller注册socket；Poller的职责是不断轮询selector, 检查准备就绪的socket(有数据可读或可写)，实现io的多路复用。Worker线程即SocketProcessor是用来处理Socket请求的。</p>
<ol>
<li>
<p>Acceptor的run方法</p>
<pre><code class="language-java">@Override
public void run() {

    int errorDelay = 0;

    // Loop until we receive a shutdown command
    while (endpoint.isRunning()) {

        // Loop if endpoint is paused
        while (endpoint.isPaused() &amp;&amp; endpoint.isRunning()) {
            state = AcceptorState.PAUSED;
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                // Ignore
            }
        }

        if (!endpoint.isRunning()) {
            break;
        }
        state = AcceptorState.RUNNING;

        try {
            //if we have reached max connections, wait
            endpoint.countUpOrAwaitConnection();

            // Endpoint might have been paused while waiting for latch
            // If that is the case, don't accept new connections
            if (endpoint.isPaused()) {
                continue;
            }

            U socket = null;
            try {
                // Accept the next incoming connection from the server
                // socket
                socket = endpoint.serverSocketAccept();
            } catch (Exception ioe) {
                // We didn't get a socket
                endpoint.countDownConnection();
                if (endpoint.isRunning()) {
                    // Introduce delay if necessary
                    errorDelay = handleExceptionWithDelay(errorDelay);
                    // re-throw
                    throw ioe;
                } else {
                    break;
                }
            }
            // Successful accept, reset the error delay
            errorDelay = 0;

            // Configure the socket
            if (endpoint.isRunning() &amp;&amp; !endpoint.isPaused()) {
                // setSocketOptions() will hand the socket off to
                // an appropriate processor if successful
                if (!endpoint.setSocketOptions(socket)) {
                    endpoint.closeSocket(socket);
                }
            } else {
                endpoint.destroySocket(socket);
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            String msg = sm.getString(&quot;endpoint.accept.fail&quot;);
            // APR specific.
            // Could push this down but not sure it is worth the trouble.
            if (t instanceof Error) {
                Error e = (Error) t;
                if (e.getError() == 233) {
                    // Not an error on HP-UX so log as a warning
                    // so it can be filtered out on that platform
                    // See bug 50273
                    log.warn(msg, t);
                } else {
                    log.error(msg, t);
                }
            } else {
                    log.error(msg, t);
            }
        }
    }
    state = AcceptorState.ENDED;
}
</code></pre>
</li>
<li>
<p>将socket注册到poller</p>
<pre><code class="language-java">/**
 * Process the specified connection.
 * @param socket The socket channel
 * @return &lt;code&gt;true&lt;/code&gt; if the socket was correctly configured
 *  and processing may continue, &lt;code&gt;false&lt;/code&gt; if the socket needs to be
 *  close immediately
 */
@Override
protected boolean setSocketOptions(SocketChannel socket) {
    // Process the connection
    try {
        // Disable blocking, polling will be used
        socket.configureBlocking(false);
        Socket sock = socket.socket();
        socketProperties.setProperties(sock);

        NioChannel channel = nioChannels.pop();
        if (channel == null) {
            SocketBufferHandler bufhandler = new SocketBufferHandler(
                    socketProperties.getAppReadBufSize(),
                    socketProperties.getAppWriteBufSize(),
                    socketProperties.getDirectBuffer());
            if (isSSLEnabled()) {
                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);
            } else {
                channel = new NioChannel(socket, bufhandler);
            }
        } else {
            channel.setIOChannel(socket);
            channel.reset();
        }
        getPoller0().register(channel);
    } catch (Throwable t) {
        ExceptionUtils.handleThrowable(t);
        try {
            log.error(sm.getString(&quot;endpoint.socketOptionsError&quot;), t);
        } catch (Throwable tt) {
            ExceptionUtils.handleThrowable(tt);
        }
        // Tell to close the socket
        return false;
    }
    return true;
}
</code></pre>
<pre><code class="language-java">/**
 * Registers a newly created socket with the poller.
 *
 * @param socket    The newly created socket
 */
public void register(final NioChannel socket) {
    socket.setPoller(this);
    NioSocketWrapper socketWrapper = new NioSocketWrapper(socket, NioEndpoint.this);
    socket.setSocketWrapper(socketWrapper);
    socketWrapper.setPoller(this);
    socketWrapper.setReadTimeout(getConnectionTimeout());
    socketWrapper.setWriteTimeout(getConnectionTimeout());
    socketWrapper.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());
    socketWrapper.setSecure(isSSLEnabled());
    PollerEvent r = eventCache.pop();
    socketWrapper.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.
    if (r == null) {
        r = new PollerEvent(socket, socketWrapper, OP_REGISTER);
    } else {
        r.reset(socket, socketWrapper, OP_REGISTER);
    }
    addEvent(r);
}
</code></pre>
</li>
<li>
<p>Poller的run 方法</p>
<pre><code class="language-java">/**
 * The background thread that adds sockets to the Poller, checks the
 * poller for triggered events and hands the associated socket off to an
 * appropriate processor as events occur.
 */
@Override
public void run() {
    // Loop until destroy() is called
    while (true) {

        boolean hasEvents = false;

        try {
            if (!close) {
                hasEvents = events();
                if (wakeupCounter.getAndSet(-1) &gt; 0) {
                    // If we are here, means we have other stuff to do
                    // Do a non blocking select
                    keyCount = selector.selectNow();
                } else {
                    keyCount = selector.select(selectorTimeout);
                }
                wakeupCounter.set(0);
            }
            if (close) {
                events();
                timeout(0, false);
                try {
                    selector.close();
                } catch (IOException ioe) {
                    log.error(sm.getString(&quot;endpoint.nio.selectorCloseFail&quot;), ioe);
                }
                break;
            }
        } catch (Throwable x) {
            ExceptionUtils.handleThrowable(x);
            log.error(sm.getString(&quot;endpoint.nio.selectorLoopError&quot;), x);
            continue;
        }
        // Either we timed out or we woke up, process events first
        if ( keyCount == 0 ) hasEvents = (hasEvents | events());

        Iterator&lt;SelectionKey&gt; iterator =
            keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;
        // Walk through the collection of ready keys and dispatch
        // any active event.
        while (iterator != null &amp;&amp; iterator.hasNext()) {
            SelectionKey sk = iterator.next();
            NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment();
            // Attachment may be null if another thread has called
            // cancelledKey()
            if (attachment == null) {
                iterator.remove();
            } else {
                iterator.remove();
                processKey(sk, attachment);
            }
        }

        // Process timeouts
        timeout(keyCount,hasEvents);
    }

    getStopLatch().countDown();
}
</code></pre>
<pre><code class="language-java">protected void processKey(SelectionKey sk, NioSocketWrapper socketWrapper) {
    try {
        if (close) {
            cancelledKey(sk);
        } else if (sk.isValid() &amp;&amp; socketWrapper != null) {
            if (sk.isReadable() || sk.isWritable()) {
                if ( socketWrapper.getSendfileData() != null ) {
                    processSendfile(sk, socketWrapper, false);
                } else {
                    unreg(sk, socketWrapper, sk.readyOps());
                    boolean closeSocket = false;
                    // Read goes before write
                    if (sk.isReadable()) {
                        if (socketWrapper.readOperation != null) {
                            getExecutor().execute(socketWrapper.readOperation);
                        } else if (!processSocket(socketWrapper, SocketEvent.OPEN_READ, true)) {
                            closeSocket = true;
                        }
                    }
                    if (!closeSocket &amp;&amp; sk.isWritable()) {
                        if (socketWrapper.writeOperation != null) {
                            getExecutor().execute(socketWrapper.writeOperation);
                        } else if (!processSocket(socketWrapper, SocketEvent.OPEN_WRITE, true)) {
                            closeSocket = true;
                        }
                    }
                    if (closeSocket) {
                        cancelledKey(sk);
                    }
                }
            }
        } else {
            // Invalid key
            cancelledKey(sk);
        }
    } catch (CancelledKeyException ckx) {
        cancelledKey(sk);
    } catch (Throwable t) {
        ExceptionUtils.handleThrowable(t);
        log.error(sm.getString(&quot;endpoint.nio.keyProcessingError&quot;), t);
    }
}
</code></pre>
</li>
<li>
<p>Worker进程实际处理用户请求</p>
<pre><code class="language-java">/**
 * Process the given SocketWrapper with the given status. Used to trigger
 * processing as if the Poller (for those endpoints that have one)
 * selected the socket.
 *
 * @param socketWrapper The socket wrapper to process
 * @param event         The socket event to be processed
 * @param dispatch      Should the processing be performed on a new
 *                          container thread
 *
 * @return if processing was triggered successfully
 */
public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,
        SocketEvent event, boolean dispatch) {
    try {
        if (socketWrapper == null) {
            return false;
        }
        SocketProcessorBase&lt;S&gt; sc = processorCache.pop();
        if (sc == null) {
            sc = createSocketProcessor(socketWrapper, event);
        } else {
            sc.reset(socketWrapper, event);
        }
        Executor executor = getExecutor();
        if (dispatch &amp;&amp; executor != null) {
            executor.execute(sc);
        } else {
            sc.run();
        }
    } catch (RejectedExecutionException ree) {
        getLog().warn(sm.getString(&quot;endpoint.executor.fail&quot;, socketWrapper) , ree);
        return false;
    } catch (Throwable t) {
        ExceptionUtils.handleThrowable(t);
        // This means we got an OOM or similar creating a thread, or that
        // the pool and its queue are full
        getLog().error(sm.getString(&quot;endpoint.process.fail&quot;), t);
        return false;
    }
    return true;
}
</code></pre>
<pre><code class="language-java">@Override
protected SocketProcessorBase&lt;NioChannel&gt; createSocketProcessor(
        SocketWrapperBase&lt;NioChannel&gt; socketWrapper, SocketEvent event) {
    return new SocketProcessor(socketWrapper, event);
}
</code></pre>
<pre><code class="language-java">protected class SocketProcessor extends SocketProcessorBase&lt;NioChannel&gt; {

    public SocketProcessor(SocketWrapperBase&lt;NioChannel&gt; socketWrapper, SocketEvent event) {
        super(socketWrapper, event);
    }

    @Override
    protected void doRun() {
        NioChannel socket = socketWrapper.getSocket();
        SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector());

        try {
            int handshake = -1;

            try {
                if (key != null) {
                    if (socket.isHandshakeComplete()) {
                        // No TLS handshaking required. Let the handler
                        // process this socket / event combination.
                        handshake = 0;
                    } else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||
                            event == SocketEvent.ERROR) {
                        // Unable to complete the TLS handshake. Treat it as
                        // if the handshake failed.
                        handshake = -1;
                    } else {
                        handshake = socket.handshake(key.isReadable(), key.isWritable());
                        // The handshake process reads/writes from/to the
                        // socket. status may therefore be OPEN_WRITE once
                        // the handshake completes. However, the handshake
                        // happens when the socket is opened so the status
                        // must always be OPEN_READ after it completes. It
                        // is OK to always set this as it is only used if
                        // the handshake completes.
                        event = SocketEvent.OPEN_READ;
                    }
                }
            } catch (IOException x) {
                handshake = -1;
                if (log.isDebugEnabled()) log.debug(&quot;Error during SSL handshake&quot;,x);
            } catch (CancelledKeyException ckx) {
                handshake = -1;
            }
            if (handshake == 0) {
                SocketState state = SocketState.OPEN;
                // Process the request from this socket
                if (event == null) {
                    state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);
                } else {
                    state = getHandler().process(socketWrapper, event);
                }
                if (state == SocketState.CLOSED) {
                    close(socket, key);
                }
            } else if (handshake == -1 ) {
                close(socket, key);
            } else if (handshake == SelectionKey.OP_READ){
                socketWrapper.registerReadInterest();
            } else if (handshake == SelectionKey.OP_WRITE){
                socketWrapper.registerWriteInterest();
            }
        } catch (CancelledKeyException cx) {
            socket.getPoller().cancelledKey(key);
        } catch (VirtualMachineError vme) {
            ExceptionUtils.handleThrowable(vme);
        } catch (Throwable t) {
            log.error(sm.getString(&quot;endpoint.processing.fail&quot;), t);
            socket.getPoller().cancelledKey(key);
        } finally {
            socketWrapper = null;
            event = null;
            //return to cache
            if (running &amp;&amp; !paused) {
                processorCache.push(this);
            }
        }
    }
}
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[源码阅读-HashMap ConcurrentHashMap]]></title>
        <id>https://caijh.github.io//post/yuan-ma-yue-du-hashmap-concurrenthashmap</id>
        <link href="https://caijh.github.io//post/yuan-ma-yue-du-hashmap-concurrenthashmap">
        </link>
        <updated>2019-07-03T03:17:17.000Z</updated>
        <summary type="html"><![CDATA[<p>搬砖自 https://mp.weixin.qq.com/s/DTzd3jdtnnveffL-zcpmyg</p>
<p>前言<br>
Map 这样的 Key Value 在软件开发中是非常经典的结构，常用于在内存中存放数据。</p>
<p>本篇主要想讨论 ConcurrentHashMap 这样一个并发容器，在正式开始之前我觉得有必要谈谈 HashMap，没有它就不会有后面的 ConcurrentHashMap。</p>
]]></summary>
        <content type="html"><![CDATA[<p>搬砖自 https://mp.weixin.qq.com/s/DTzd3jdtnnveffL-zcpmyg</p>
<p>前言<br>
Map 这样的 Key Value 在软件开发中是非常经典的结构，常用于在内存中存放数据。</p>
<p>本篇主要想讨论 ConcurrentHashMap 这样一个并发容器，在正式开始之前我觉得有必要谈谈 HashMap，没有它就不会有后面的 ConcurrentHashMap。</p>
<!-- more -->
<h4 id="hashmap">HashMap</h4>
<p>众所周知 HashMap 底层是基于 数组 + 链表 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。</p>
<h5 id="base-17">Base 1.7</h5>
<p>1.7 中的数据结构图：<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuniawDic6DVLxibmw3cLgbicF8ibyajrpibGcbezT6TWR0ibJcDmnHmwuss7ZQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""><br>
先来看看 1.7 中的实现。<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuzYhM1hVO4fokTzXoDrcy5zjRLibfXhhF1QrWxXu3S9uVACrAbcLjNvg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>这是 HashMap 中比较核心的几个成员变量；看看分别是什么意思？</p>
<ol>
<li>初始化桶大小，因为底层是数组，所以这是数组默认的大小。</li>
<li>桶最大值。</li>
<li>默认的负载因子（0.75）</li>
<li>table 真正存放数据的数组。</li>
<li>Map 存放数量的大小。</li>
<li>桶大小，可在初始化时显式指定。</li>
<li>负载因子，可在初始化时显式指定。</li>
</ol>
<p>重点解释下负载因子：</p>
<p>由于给定的 HashMap 的容量大小是固定的，比如默认初始化：</p>
<pre><code> 1    public HashMap() {
 2        this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);
 3    }
 4
 5    public HashMap(int initialCapacity, float loadFactor) {
 6        if (initialCapacity &lt; 0)
 7            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +
 8                                               initialCapacity);
 9        if (initialCapacity &gt; MAXIMUM_CAPACITY)
10            initialCapacity = MAXIMUM_CAPACITY;
11        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))
12            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +
13                                               loadFactor);
14
15        this.loadFactor = loadFactor;
16        threshold = initialCapacity;
17        init();
18    }
</code></pre>
<p>给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。</p>
<p>因此通常建议能提前预估 HashMap 的大小最好，尽量的减少扩容带来的性能损耗。</p>
<p>根据代码可以看到其实真正存放数据的是</p>
<p><code>transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;</code></p>
<p>这个数组，那么它又是如何定义的呢？<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuX0o4uxUqo3XFULiaWedAr9z48BjRicBLaLLq9muCt1ftNafgJDyWKribg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>Entry 是 HashMap 中的一个内部类，从他的成员变量很容易看出：</p>
<ul>
<li>key 就是写入时的键。</li>
<li>value 自然就是值。</li>
<li>开始的时候就提到 HashMap 是由数组和链表组成，所以这个 next 就是用于实现链表结构。</li>
<li>hash 存放的是当前 key 的 hashcode。</li>
</ul>
<p>知晓了基本结构，那来看看其中重要的写入、获取函数：</p>
<p>put 方法</p>
<pre><code> 1    public V put(K key, V value) {
 2        if (table == EMPTY_TABLE) {
 3            inflateTable(threshold);
 4        }
 5        if (key == null)
 6            return putForNullKey(value);
 7        int hash = hash(key);
 8        int i = indexFor(hash, table.length);
 9        for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) {
10            Object k;
11            if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {
12                V oldValue = e.value;
13                e.value = value;
14                e.recordAccess(this);
15                return oldValue;
16            }
17        }
18
19        modCount++;
20        addEntry(hash, key, value, i);
21        return null;
22    }
</code></pre>
<ul>
<li>判断当前数组是否需要初始化。</li>
<li>如果 key 为空，则 put 一个空值进去。</li>
<li>根据 key 计算出 hashcode。</li>
<li>根据计算出的 hashcode 定位出所在桶。</li>
<li>如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。</li>
</ul>
<p>如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。</p>
<pre><code> 1    void addEntry(int hash, K key, V value, int bucketIndex) {
 2        if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) {
 3            resize(2 * table.length);
 4            hash = (null != key) ? hash(key) : 0;
 5            bucketIndex = indexFor(hash, table.length);
 6        }
 7
 8        createEntry(hash, key, value, bucketIndex);
 9    }
10
11    void createEntry(int hash, K key, V value, int bucketIndex) {
12        Entry&lt;K,V&gt; e = table[bucketIndex];
13        table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);
14        size++;
15    }
</code></pre>
<ul>
<li>
<p>当调用 addEntry 写入 Entry 时需要判断是否需要扩容。</p>
</li>
<li>
<p>如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位。</p>
</li>
<li>
<p>而在 createEntry 中会将当前位置的桶传入到新建的桶中，如果当前桶有值就会在位置形成链表。</p>
</li>
</ul>
<p>get 方法<br>
再来看看 get 函数：</p>
<pre><code> 1    public V get(Object key) {
 2        if (key == null)
 3            return getForNullKey();
 4        Entry&lt;K,V&gt; entry = getEntry(key);
 5
 6        return null == entry ? null : entry.getValue();
 7    }
 8
 9    final Entry&lt;K,V&gt; getEntry(Object key) {
10        if (size == 0) {
11            return null;
12        }
13
14        int hash = (key == null) ? 0 : hash(key);
15        for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)];
16             e != null;
17             e = e.next) {
18            Object k;
19            if (e.hash == hash &amp;&amp;
20                ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
21                return e;
22        }
23        return null;
24    }
</code></pre>
<ul>
<li>首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。<br>
判断该位置是否为链表。</li>
<li>不是链表就根据 key、key 的 hashcode 是否相等来返回值。</li>
<li>为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。</li>
<li>啥都没取到就直接返回 null 。</li>
</ul>
<p>Base 1.8<br>
不知道 1.7 的实现大家看出需要优化的点没有？<br>
其实一个很明显的地方就是：</p>
<blockquote>
<p>当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)。<br>
因此 1.8 中重点优化了这个查询效率。</p>
</blockquote>
<p>1.8 HashMap 结构图：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuFVB8SHEbdxmchRiakoeFXwlzQUX5ld65WsGsPGZ2n7UMWcu3y2hl1QQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>先来看看几个核心的成员变量：</p>
<pre><code> 1    static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16
 2
 3    /**
 4     * The maximum capacity, used if a higher value is implicitly specified
 5     * by either of the constructors with arguments.
 6     * MUST be a power of two &lt;= 1&lt;&lt;30.
 7     */
 8    static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
 9
10    /**
11     * The load factor used when none specified in constructor.
12     */
13    static final float DEFAULT_LOAD_FACTOR = 0.75f;
14
15    static final int TREEIFY_THRESHOLD = 8;
16
17    transient Node&lt;K,V&gt;[] table;
18
19    /**
20     * Holds cached entrySet(). Note that AbstractMap fields are used
21     * for keySet() and values().
22     */
23    transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;
24
25    /**
26     * The number of key-value mappings contained in this map.
27     */
28    transient int size;
</code></pre>
<p>和 1.7 大体上都差不多，还是有几个重要的区别：</p>
<ul>
<li>TREEIFY_THRESHOLD 用于判断是否需要将链表转换为红黑树的阈值。</li>
<li>HashEntry 修改为 Node。</li>
<li>Node 的核心组成其实也是和 1.7 中的 HashEntry 一样，存放的都是 key value hashcode next 等数据。</li>
</ul>
<p>再来看看核心方法。</p>
<p>put 方法<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJu4UWuTyDjAgliaaiaD7QbiaSgcQSpuzyCI03VUHeU4mias8jExp4KoS7HAg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>看似要比 1.7 的复杂，我们一步步拆解：</p>
<ol>
<li>判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。</li>
<li>根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。</li>
<li>如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。</li>
<li>如果当前桶为红黑树，那就要按照红黑树的方式写入数据。</li>
<li>如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。</li>
<li>接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。</li>
<li>如果在遍历过程中找到 key 相同时直接退出遍历。</li>
<li>如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。</li>
</ol>
<p>最后判断是否需要进行扩容。</p>
<p>get 方法</p>
<pre><code> 1    public V get(Object key) {
 2        Node&lt;K,V&gt; e;
 3        return (e = getNode(hash(key), key)) == null ? null : e.value;
 4    }
 5
 6    final Node&lt;K,V&gt; getNode(int hash, Object key) {
 7        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
 8        if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
 9            (first = tab[(n - 1) &amp; hash]) != null) {
10            if (first.hash == hash &amp;&amp; // always check first node
11                ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
12                return first;
13            if ((e = first.next) != null) {
14                if (first instanceof TreeNode)
15                    return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);
16                do {
17                    if (e.hash == hash &amp;&amp;
18                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
19                        return e;
20                } while ((e = e.next) != null);
21            }
22        }
23        return null;
24    }
</code></pre>
<p>get 方法看起来就要简单许多了。</p>
<ol>
<li>首先将 key hash 之后取得所定位的桶。</li>
<li>如果桶为空则直接返回 null 。</li>
<li>否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。</li>
<li>如果第一个不匹配，则判断它的下一个是红黑树还是链表。</li>
<li>红黑树就按照树的查找方式返回值。</li>
<li>不然就按照链表的方式遍历匹配返回值。</li>
</ol>
<p>从这两个核心方法（get/put）可以看出 1.8 中对大链表做了优化，修改为红黑树之后查询效率直接提高到了 O(logn)。</p>
<p>但是 HashMap 原有的问题也都存在，比如在并发场景下使用时容易出现死循环。</p>
<pre><code>1final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();
2for (int i = 0; i &lt; 1000; i++) {
3    new Thread(new Runnable() {
4        @Override
5        public void run() {
6            map.put(UUID.randomUUID().toString(), &quot;&quot;);
7        }
8    }).start();
9}
</code></pre>
<p>但是为什么呢？简单分析下。</p>
<p>看过上文的还记得在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。</p>
<p>如下图：<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJu43gK5Lic4AUj9LBR0xMtVYYwIicM0I6GnyyqqHXv1ClnNrLvXYics71Mw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>遍历方式<br>
还有一个值得注意的是 HashMap 的遍历方式，通常有以下几种：</p>
<pre><code> 1Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator();
 2        while (entryIterator.hasNext()) {
 3            Map.Entry&lt;String, Integer&gt; next = entryIterator.next();
 4            System.out.println(&quot;key=&quot; + next.getKey() + &quot; value=&quot; + next.getValue());
 5        }
 6
 7Iterator&lt;String&gt; iterator = map.keySet().iterator();
 8        while (iterator.hasNext()){
 9            String key = iterator.next();
10            System.out.println(&quot;key=&quot; + key + &quot; value=&quot; + map.get(key));
11
12        }
</code></pre>
<p>强烈建议使用第一种 EntrySet 进行遍历。</p>
<p>第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低。</p>
<p>简单总结下 HashMap：无论是 1.7 还是 1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至出现死循环导致系统不可用。</p>
<p>因此 JDK 推出了专项专用的 ConcurrentHashMap ，该类位于 java.util.concurrent 包下，专门用于解决并发问题。</p>
<p>坚持看到这里的朋友算是已经把 ConcurrentHashMap 的基础已经打牢了，下面正式开始分析。</p>
<p>ConcurrentHashMap<br>
ConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。</p>
<p>Base 1.7<br>
先来看看 1.7 的实现，下面是他的结构图：<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuFYL4rHqAwSJOQXIBqL76h5M8hnOJdaVowDrHicIZ4LTYtKDPBa2Bl9Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。</p>
<p>它的核心成员变量：</p>
<pre><code>1    /**
2     * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。
3     */
4    final Segment&lt;K,V&gt;[] segments;
5
6    transient Set&lt;K&gt; keySet;
7    transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;
Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下：

 1    static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {
 2
 3        private static final long serialVersionUID = 2249069246763182397L;
 4
 5        // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶
 6        transient volatile HashEntry&lt;K,V&gt;[] table;
 7
 8        transient int count;
 9
10        transient int modCount;
11
12        transient int threshold;
13
14        final float loadFactor;
15
16    }
</code></pre>
<p>看看其中 HashEntry 的组成：<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuDFkA8uvql3mGTNqibibfuEOnjjC9FAB8VZwR0TazTgKf0MlhGrCXv7Sw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。</p>
<p>原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。</p>
<p>下面也来看看核心的 put get 方法。</p>
<pre><code>put 方法
 1    public V put(K key, V value) {
 2        Segment&lt;K,V&gt; s;
 3        if (value == null)
 4            throw new NullPointerException();
 5        int hash = hash(key);
 6        int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;
 7        if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject          // nonvolatile; recheck
 8             (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //  in ensureSegment
 9            s = ensureSegment(j);
10        return s.put(key, hash, value, false);
11    }
</code></pre>
<p>首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。</p>
<pre><code> 1        final V put(K key, int hash, V value, boolean onlyIfAbsent) {
 2            HashEntry&lt;K,V&gt; node = tryLock() ? null :
 3                scanAndLockForPut(key, hash, value);
 4            V oldValue;
 5            try {
 6                HashEntry&lt;K,V&gt;[] tab = table;
 7                int index = (tab.length - 1) &amp; hash;
 8                HashEntry&lt;K,V&gt; first = entryAt(tab, index);
 9                for (HashEntry&lt;K,V&gt; e = first;;) {
10                    if (e != null) {
11                        K k;
12                        if ((k = e.key) == key ||
13                            (e.hash == hash &amp;&amp; key.equals(k))) {
14                            oldValue = e.value;
15                            if (!onlyIfAbsent) {
16                                e.value = value;
17                                ++modCount;
18                            }
19                            break;
20                        }
21                        e = e.next;
22                    }
23                    else {
24                        if (node != null)
25                            node.setNext(first);
26                        else
27                            node = new HashEntry&lt;K,V&gt;(hash, key, value, first);
28                        int c = count + 1;
29                        if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)
30                            rehash(node);
31                        else
32                            setEntryAt(tab, index, node);
33                        ++modCount;
34                        count = c;
35                        oldValue = null;
36                        break;
37                    }
38                }
39            } finally {
40                unlock();
41            }
42            return oldValue;
43        }
</code></pre>
<p>虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。</p>
<p>首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuQahXKiaeuX1t5Xn8vqMhDpCic05KvuyvN5lrrK17BlDiaE2Qrh4aw9KAQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<ol>
<li>尝试自旋获取锁。</li>
<li>如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。<br>
<img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJu5DphFu4lllNoynBAIK4Xzl4ZgTneCUkHYfibBIwFIamnYOGATYUpC5A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></li>
</ol>
<p>再结合图看看 put 的流程。<br>
1.将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。<br>
2. 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。<br>
3. 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。<br>
4.最后会解除在 1 中所获取当前 Segment 的锁。</p>
<p>get 方法</p>
<pre><code> 1    public V get(Object key) {
 2        Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead
 3        HashEntry&lt;K,V&gt;[] tab;
 4        int h = hash(key);
 5        long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;
 6        if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;
 7            (tab = s.table) != null) {
 8            for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile
 9                     (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE);
10                 e != null; e = e.next) {
11                K k;
12                if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k)))
13                    return e.value;
14            }
15        }
16        return null;
17    }
</code></pre>
<p>get 逻辑比较简单：</p>
<p>只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。</p>
<p>由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。</p>
<p>ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。</p>
<p>Base 1.8<br>
1.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。</p>
<p>那就是查询遍历链表效率太低。</p>
<p>因此 1.8 做了一些数据结构上的调整。</p>
<p>首先来看下底层的组成结构：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuUfRMPmJ4ib95BpUVDkecPy5kBCXxdq15XzO6MMhH5FRvsADhwFXZI5Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>看起来是不是和 1.8 HashMap 结构类似？</p>
<p>其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuX0QiaOcnzqugCVfdNR0KRDHlMOic8Pn7TZ0BcG8Oc1NBiaZSgVsmQGt2g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。</p>
<p>其中的 val next 都用了 volatile 修饰，保证了可见性。</p>
<p>put 方法<br>
重点来看看 put 函数：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJu606XAOtEmOlp5WZyCNUL2PklOSq1SgbWtoNy06MpyVW3euNqibLRibWg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>根据 key 计算出 hashcode 。</p>
<p>判断是否需要进行初始化。</p>
<p>f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。</p>
<p>如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。</p>
<p>如果都不满足，则利用 synchronized 锁写入数据。</p>
<p>如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。</p>
<p>get 方法</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/csD7FygBVl2YrHfgckicQvCZFaT240KJuKGCGoSfbyPIEV7gea97OXFVVicDU4qYicxprd6xJjeLcfjQUTgBIqBaA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。</p>
<p>如果是红黑树那就按照树的方式获取值。</p>
<p>就不满足那就按照链表的方式遍历获取值。</p>
<p>1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。</p>
<p>总结<br>
看完了整个 HashMap 和 ConcurrentHashMap 在 1.7 和 1.8 中不同的实现方式相信大家对他们的理解应该会更加到位。</p>
<p>其实这块也是面试的重点内容，通常的套路是：</p>
<p>谈谈你理解的 HashMap，讲讲其中的 get put 过程。</p>
<p>1.8 做了什么优化？</p>
<p>是线程安全的嘛？</p>
<p>不安全会导致哪些问题？</p>
<p>如何解决？有没有线程安全的并发容器？</p>
<p>ConcurrentHashMap 是如何实现的？ 1.7、1.8 实现有何不同？为什么这么做？</p>
<p>这一串问题相信大家仔细看完都能怼回面试官</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[maven-发布自己的maven构件到中央仓库]]></title>
        <id>https://caijh.github.io//post/maven-fa-bu-zi-ji-de-maven-gou-jian-dao-zhong-yang-cang-ku</id>
        <link href="https://caijh.github.io//post/maven-fa-bu-zi-ji-de-maven-gou-jian-dao-zhong-yang-cang-ku">
        </link>
        <updated>2019-07-02T14:42:43.000Z</updated>
        <summary type="html"><![CDATA[<p>发布自己的jar包到中央仓库的好处：</p>
<ol>
<li>省去自建maven私服</li>
<li>方便自己或者别个在他处引用jar包</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<p>发布自己的jar包到中央仓库的好处：</p>
<ol>
<li>省去自建maven私服</li>
<li>方便自己或者别个在他处引用jar包</li>
</ol>
<!-- more -->
<h2 id="注册-sonatype的jira-帐号">注册 sonatype的Jira 帐号</h2>
<p>注册地址: https://issues.sonatype.org/secure/Signup!default.jspa<br>
注册很简单,重要的是邮箱地址一定要正确,issue有任何变动都会通过邮件通知.</p>
<h2 id="登录jira">登录Jira</h2>
<p>注册完成后就登录: https://issues.sonatype.org/login.jsp</p>
<h2 id="创建一个-issue">创建一个 Issue</h2>
<p>创建地址: https://issues.sonatype.org/secure/CreateIssue.jspa?issuetype=21&amp;pid=10134</p>
<h2 id="使用-gpg-生成密钥对">使用 GPG 生成密钥对</h2>
<ol>
<li>
<p>查看gpg安装版本</p>
<pre><code>gpg --version
</code></pre>
</li>
<li>
<p>生成密钥对</p>
</li>
<li>
<p>查看公钥</p>
<pre><code>gpg --list-keys
</code></pre>
</li>
<li>
<p>将公钥发布到 PGP 密钥服务器</p>
<pre><code>gpg --keyserver hkp://pool.sks-keyservers.net --send-keys 你的公钥指纹
</code></pre>
</li>
</ol>
<h2 id="修改maven的settingxml文件">修改maven的setting.xml文件</h2>
<pre><code>&lt;server&gt;
      &lt;id&gt;oss&lt;/id&gt;
      &lt;username&gt;sonatype.org的用户名&lt;/username&gt;
      &lt;password&gt;sonatype.org的密码&lt;/password&gt;
    &lt;/server&gt;
    
&lt;profile&gt;
       &lt;id&gt;gpg&lt;/id&gt;
       &lt;properties&gt;
          &lt;gpg.executable&gt;gpg&lt;/gpg.executable&gt;
          &lt;gpg.keyname&gt;公钥&lt;/gpg.keyname&gt;
          &lt;gpg.passphrase&gt;gpg的passphrase&lt;/gpg.passphrase&gt;
       &lt;/properties&gt;
    &lt;/profile&gt;
    
&lt;activeProfiles&gt;
    &lt;activeProfile&gt;gpg&lt;/activeProfile&gt;
  &lt;/activeProfiles&gt;
</code></pre>
<h2 id="修改pomxml文件">修改pom.xml文件</h2>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.0.2.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;

    &lt;groupId&gt;com.github.caijh&lt;/groupId&gt;
    &lt;artifactId&gt;service-parent&lt;/artifactId&gt;
    &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;pom&lt;/packaging&gt;

    &lt;properties&gt;
        &lt;!-- 文件拷贝时的编码 --&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
        &lt;!-- 编译时的编码 --&gt;
        &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;
    &lt;/properties&gt;

    &lt;licenses&gt;
        &lt;license&gt;
            &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;
            &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;
        &lt;/license&gt;
    &lt;/licenses&gt;
    &lt;developers&gt;
        &lt;developer&gt;
            &lt;name&gt;caijunhui&lt;/name&gt;
            &lt;email&gt;caiqizhe@gmail.com&lt;/email&gt;
        &lt;/developer&gt;
    &lt;/developers&gt;
    &lt;scm&gt;
        &lt;connection&gt;scm:git:git@github.com:caijh/service-parent.git&lt;/connection&gt;
        &lt;developerConnection&gt;scm:git:git@github.com:caijh/service-parent.git&lt;/developerConnection&gt;
        &lt;url&gt;git@github.com:caijh/service-parent.git&lt;/url&gt;
    &lt;/scm&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;
            &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;
            &lt;version&gt;2.3.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt;
            &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt;
            &lt;version&gt;2.3.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt;
            &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt;
            &lt;version&gt;2.3.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.activation&lt;/groupId&gt;
            &lt;artifactId&gt;activation&lt;/artifactId&gt;
            &lt;version&gt;1.1.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.inject&lt;/groupId&gt;
            &lt;artifactId&gt;javax.inject&lt;/artifactId&gt;
            &lt;version&gt;1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.javassist&lt;/groupId&gt;
            &lt;artifactId&gt;javassist&lt;/artifactId&gt;
            &lt;version&gt;3.25.0-GA&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
            &lt;version&gt;1.2.58&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt;
            &lt;artifactId&gt;jsr305&lt;/artifactId&gt;
            &lt;version&gt;3.0.2&lt;/version&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;

    &lt;profiles&gt;
        &lt;profile&gt;
            &lt;id&gt;release&lt;/id&gt;
            &lt;build&gt;
                &lt;plugins&gt;
                    &lt;!-- Source --&gt;
                    &lt;plugin&gt;
                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                        &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
                        &lt;version&gt;3.1.0&lt;/version&gt;
                        &lt;executions&gt;
                            &lt;execution&gt;
                                &lt;phase&gt;package&lt;/phase&gt;
                                &lt;goals&gt;
                                    &lt;goal&gt;jar-no-fork&lt;/goal&gt;
                                &lt;/goals&gt;
                            &lt;/execution&gt;
                        &lt;/executions&gt;
                    &lt;/plugin&gt;
                    &lt;!-- Javadoc --&gt;
                    &lt;plugin&gt;
                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                        &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;
                        &lt;version&gt;3.1.0&lt;/version&gt;
                        &lt;configuration&gt;
                            &lt;show&gt;private&lt;/show&gt;
                            &lt;nohelp&gt;true&lt;/nohelp&gt;
                            &lt;charset&gt;UTF-8&lt;/charset&gt;
                            &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                            &lt;docencoding&gt;UTF-8&lt;/docencoding&gt;
                            &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt;  &lt;!-- TODO 临时解决不规范的javadoc生成报错,后面要规范化后把这行去掉 --&gt;
                        &lt;/configuration&gt;
                        &lt;executions&gt;
                            &lt;execution&gt;
                                &lt;phase&gt;package&lt;/phase&gt;
                                &lt;goals&gt;
                                    &lt;goal&gt;jar&lt;/goal&gt;
                                &lt;/goals&gt;
                            &lt;/execution&gt;
                        &lt;/executions&gt;
                    &lt;/plugin&gt;
                    &lt;!-- GPG --&gt;
                    &lt;plugin&gt;
                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                        &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt;
                        &lt;version&gt;1.6&lt;/version&gt;
                        &lt;executions&gt;
                            &lt;execution&gt;
                                &lt;id&gt;sign-artifacts&lt;/id&gt;
                                &lt;phase&gt;verify&lt;/phase&gt;
                                &lt;goals&gt;
                                    &lt;goal&gt;sign&lt;/goal&gt;
                                &lt;/goals&gt;
                                &lt;configuration&gt;
                                    &lt;gpgArguments&gt;
                                        &lt;arg&gt;--pinentry-mode&lt;/arg&gt;
                                        &lt;arg&gt;loopback&lt;/arg&gt;
                                    &lt;/gpgArguments&gt;
                                &lt;/configuration&gt;
                            &lt;/execution&gt;
                        &lt;/executions&gt;
                    &lt;/plugin&gt;
                &lt;/plugins&gt;
            &lt;/build&gt;
            &lt;distributionManagement&gt;
                &lt;snapshotRepository&gt;
                    &lt;id&gt;oss&lt;/id&gt;
                    &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt;
                &lt;/snapshotRepository&gt;
                &lt;repository&gt;
                    &lt;id&gt;oss&lt;/id&gt;
                    &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;
                &lt;/repository&gt;
            &lt;/distributionManagement&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;


&lt;/project&gt;
</code></pre>
<h2 id="发布到oss中">发布到OSS中</h2>
<pre><code>mvn clean deploy -P release
</code></pre>
<h2 id="遇到的问题">遇到的问题</h2>
<ol>
<li>
<p>maven-source-plugin等插件not found</p>
</li>
<li>
<p>execute gobal gpg error, 加入以下配置解决</p>
<configuration>
          <gpgArguments>
                    <arg>--pinentry-mode</arg>
                    <arg>loopback</arg>
                    </gpgArguments>
</configuration></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[源码阅读-HashMap的实现原理]]></title>
        <id>https://caijh.github.io//post/yuan-ma-yue-du-hashmap-de-shi-xian-yuan-li</id>
        <link href="https://caijh.github.io//post/yuan-ma-yue-du-hashmap-de-shi-xian-yuan-li">
        </link>
        <updated>2019-07-01T09:38:57.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>原文链接：https://blog.csdn.net/fenglibing/article/details/91565912</p>
</blockquote>
<h3 id="hashmap的类图">HashMap的类图</h3>
<p><img src="https://caijh.github.io//post-images/1561974106214.png" alt=""></p>
<p>HashMap是Java开发当中使用得非常多的一种数据结构，因为其可以快速的定位到需要查找到数据，其最快的速度可以达到O(1)，最差的时候也可以达到O(n)。本文以Java8中的HashMap做为分析原型，因为不同的JDK版本中的HashMap，可能存在着底层实现上的不一样。</p>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>原文链接：https://blog.csdn.net/fenglibing/article/details/91565912</p>
</blockquote>
<h3 id="hashmap的类图">HashMap的类图</h3>
<p><img src="https://caijh.github.io//post-images/1561974106214.png" alt=""></p>
<p>HashMap是Java开发当中使用得非常多的一种数据结构，因为其可以快速的定位到需要查找到数据，其最快的速度可以达到O(1)，最差的时候也可以达到O(n)。本文以Java8中的HashMap做为分析原型，因为不同的JDK版本中的HashMap，可能存在着底层实现上的不一样。</p>
<!-- more -->
<p>HashMap是通过数组存储所有的数据，每个元素所存放数组的下标，是根据该存储元素的key的Hash值与该数组的长度减去1做与运算，如下所示：</p>
<pre><code>index = (length_of_array - 1) &amp; hash_of_the_key;
</code></pre>
<p>数组中存放元素的数据结构使用了Node和TreeNode两种数据结构，在单个Hash值对应的存储元素小于8个时，默认值为Node的单向链表形式存储，当单个Hash值存储的元素大于8个时，其会使用TreeNode的数据结构存储。</p>
<p>因为在单个Hash值对应的元素小于等于8个时，其查询时间最差为O(8)，但是当单个Hash值对应的元素大于8个时，再通过Node的单向链表的方式进行查询，速度上就会变得更慢了；这个时候HashMap就会将Node的普通节点转为TreeNode（红黑树）进行存储，这是由于TreeNode占用的空间大小约为常规节点的两倍，但是其查询速度可以得到保证，这个是通过空间换时间了。当TreeNode中包括的元素变得比较少时，为了存储空间的占用，也会转换为Node节点单向链表的方式实现，它们之间可以互相转换的。</p>
<h4 id="node">Node：</h4>
<pre><code>static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
        final int hash;
        final K key;
        V value;
        Node&lt;K,V&gt; next;

        Node(int hash, K key, V value, Node&lt;K,V&gt; next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
        ......
}
</code></pre>
<p>可以看到每个Node中包括了4个属性，分别为：</p>
<pre><code>hash值：当前Node的Hash值
key：当前Node的key
value:当前Node的value
next:表示指向下一个Node的指针，相同hash值的Node，通过next进行遍历查找
</code></pre>
<h4 id="treenode">TreeNode：</h4>
<pre><code>static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; {
        TreeNode&lt;K,V&gt; parent;  // red-black tree links
        TreeNode&lt;K,V&gt; left;
        TreeNode&lt;K,V&gt; right;
        TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion
        boolean red;
        TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) {
            super(hash, key, val, next);
        }
        ......
}
</code></pre>
<p>可以看到TreeNode使用的是红黑树（Red Black Tree）的数据结构，红黑树是一种自平衡二叉查找树，在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，即使在最坏情况运行时间也是非常良好的，并且在实践中是非常高效的，它可以在O(log n)时间内做查找、插入和删除等操作，这里的n 是树中元素的数目。</p>
<p>以下是一张关于HashMap存储结构的示意图：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/5833578-bba5d27f64076c52?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<h4 id="写入数据一切皆在注释中">写入数据（一切皆在注释中）</h4>
<p>其方法如下：</p>
<pre><code>//写入数据
public V put(K key, V value) {
	//首先根据hash方法，获取对应key的hash值，计算方法见后面
    return putVal(hash(key), key, value, false, true);
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
	//判断用户存放元素的数组是否为空
    if ((tab = table) == null || (n = tab.length) == 0)
        //为空则进行初使化，并将初使化后的数组赋值给变量tab，数组的长值赋值给变量n
        n = (tab = resize()).length;
	//判断根据hash值与数组长度减1求与得到的下标，
	//从数组中获取元素并将其赋值给变量p(后续该变量p可以继续使用)，并判断该元素是否存在
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        //如果不存在则创建一个新的节点，并将其放到数组对应的下标中
        tab[i] = newNode(hash, key, value, null);
    else {//根据数组的下标取到了元素，并且该元素p且不为空，下面要判断p元素的类型是Node还是TreeNode
        Node&lt;K,V&gt; e; K k;
        //判断该数组对应下标取到的第一值是不是与正在存入值的hash值相同、
        //key相等（可能是对象，也可能是字符串），如果相等，则将取第一个值赋值给变量e
        if (p.hash == hash &amp;&amp;
            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;
        //判断取的对象是不是TreeNode，如果是则执行TreeNode的put方法
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
        else {//是普通的Node节点，
        	//根据next属性对元素p执行单向链表的遍历
            for (int binCount = 0; ; ++binCount) {
                //如果被遍历的元素最后的next为空，表示后面没有节点了，则将新节点与当前节点的next属性建立关系
                if ((e = p.next) == null) {
                	//做为当前节点的后面的一个节点
                    p.next = newNode(hash, key, value, null);
                	//判断当前节点的单向链接的数量（8个）是不是已经达到了需要将其转换为TreeNode了
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //如果是则将当前数组下标对应的元素转换为TreeNode
                        treeifyBin(tab, hash);
                    break;
                }
                //判断待插入的元素的hash值与key是否与单向链表中的某个元素的hash值与key是相同的，如果是则退出
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    break;
                p = e;
            }
        }
        //判断是否找到了与待插入元素的hash值与key值都相同的元素
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
        	//判断是否要将旧值替换为新值
            if (!onlyIfAbsent || oldValue == null)
                //满足于未指定不替换或旧值为空的情况，执行将旧值替换为新值
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>
<p>Hash值的计算方法：</p>
<pre><code>// 计算指定key的hash值，原理是将key的hash code与hash code无符号向右移16位的值，执行异或运算。
// 在Java中整型为4个字节32位，无符号向右移16位，表示将高16位移到低16位上，然后再执行异或运行，也 
// 就是将hash code的高16位与低16位进行异或运行。
// 小于等于65535的数，其高16位全部都为0，因而将小于等于65535的值向右无符号移16位，则该数就变成了 
// 32位都是0，由于任何数与0进行异或都等于本身，因而hash code小于等于65535的key，其得到的hash值 
// 就等于其本身的hash code。
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
</code></pre>
<h4 id="读取数据一切皆在注释中">读取数据（一切皆在注释中）</h4>
<pre><code>public V get(Object key) {
        Node&lt;K,V&gt; e;
        //根据Key获取元素
        if ((e = getNode(hash(key), key)) == null)
            return null;
        if (accessOrder)
            afterNodeAccess(e);
        return e.value;
    }

    final Node&lt;K,V&gt; getNode(int hash, Object key) {
        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
        //if语句的第一个判断条件
        if ((tab = table) != null //将数组赋值给变量tab，将判断是否为null
            &amp;&amp; (n = tab.length) &gt; 0 //将数组的长值赋值给变量n
            &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) {//判断根据hash和数组长度减1的与运算，计算出来的的数组下标的第一个元素是不是为空
        	//判断第一个元素是否要找的元素，大部份情况下只要hash值太集中，或者元素不是很多，第一个元素往往都是需要的最终元素
            if (first.hash == hash &amp;&amp; // always check first node
                ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
                //第一个元素就是要找的元素，因为hash值和key都相等，直接返回
                return first;
            if ((e = first.next) != null) {//如果第一元素不是要找到的元，则判断其next指向是否还有元素
                //有元素，判断其是否是TreeNode
                if (first instanceof TreeNode)
                	//是TreeNode则根据TreeNode的方式获取数据
                    return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);
                do {//是Node单向链表，则通过next循环匹配，找到就退出，否则直到匹配完最后一个元素才退出
                    if (e.hash == hash &amp;&amp;
                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        //没有找到则返回null
        return null;
    }
</code></pre>
]]></content>
    </entry>
</feed>